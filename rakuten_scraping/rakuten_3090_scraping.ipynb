{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Rakutenâ€¯TravelÂ ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›†Â 2024ï¼ˆçœŒåˆ¥ 70 ä»¶ / v12.1 â€” fâ€‘string ä¿®æ­£ï¼‰\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â— çœŒã”ã¨ã« 70 ä»¶ã‚’ç›®æ¨™ã« 2024 å¹´ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†\n",
    "â— 1 ãƒ›ãƒ†ãƒ«æœ€å¤§ 5 ä»¶ / 30 ãƒ›ãƒ†ãƒ«ãšã¤ä¸¦åˆ—å‡¦ç†ï¼ˆä¸è¶³æ™‚ã«è¿½åŠ ï¼‰\n",
    "â— WORKERS = RT_MAX_WORKERSï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 24ï¼‰\n",
    "\"\"\"\n",
    "\n",
    "import os, re, time, random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MAX_PER_PREF   = 70\n",
    "MAX_REV_HOTEL  = 5\n",
    "TARGET_YEAR    = \"2024å¹´\"\n",
    "MONTH_CODES    = [f\"2024{m:02d}\" for m in range(1, 13)]\n",
    "MAX_WORKERS    = int(os.getenv(\"RT_MAX_WORKERS\", 24))\n",
    "SLEEP_RANGE    = (0.05, 0.12)\n",
    "OUT_FILE       = \"japan_2024_reviews.csv\"\n",
    "UA             = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "REV_PAGE_SIZE  = 20\n",
    "MAX_PAGES_PER_M= 4    # 4*20 = 80 ãƒ¬ãƒ“ãƒ¥ãƒ¼ / ãƒ›ãƒ†ãƒ« / æœˆ\n",
    "MAX_HOTELS_PER_BATCH = 25  # 25*5 = 125 > 70 â†’ ååˆ†\n",
    "PAT_ID         = re.compile(r\"/(?:HOTEL|hotelinfo)/(\\d+)/\", re.I)\n",
    "\n",
    "PREF_SLUGS = [\n",
    "    \"hokkaido\",\"aomori\",\"iwate\",\"miyagi\",\"akita\",\"yamagata\",\"fukushima\",\n",
    "    \"ibaraki\",\"tochigi\",\"gunma\",\"saitama\",\"chiba\",\"tokyo\",\"kanagawa\",\n",
    "    \"niigata\",\"toyama\",\"ishikawa\",\"fukui\",\"yamanashi\",\"nagano\",\"gifu\",\n",
    "    \"shizuoka\",\"aichi\",\"mie\",\"shiga\",\"kyoto\",\"osaka\",\"hyogo\",\"nara\",\n",
    "    \"wakayama\",\"tottori\",\"shimane\",\"okayama\",\"hiroshima\",\"yamaguchi\",\n",
    "    \"tokushima\",\"kagawa\",\"ehime\",\"kochi\",\"fukuoka\",\"saga\",\"nagasaki\",\n",
    "    \"kumamoto\",\"oita\",\"miyazaki\",\"kagoshima\",\"okinawa\"\n",
    "]\n",
    "\n",
    "LIST_UI       = \"https://travel.rakuten.co.jp/yado/{slug}/?page={page}\"\n",
    "LIST_FALLBACK = \"https://travel.rakuten.co.jp/office/pref/{slug}.html?p={page}\"\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HTTP ã‚»ãƒƒã‚·ãƒ§ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "_session = requests.Session()\n",
    "_session.mount(\"https://\", HTTPAdapter(pool_maxsize=MAX_WORKERS*2))\n",
    "_session.headers.update(UA)\n",
    "\n",
    "\n",
    "def http_get(url: str, **kw):\n",
    "    \"\"\"GET with up to 3 retries.\"\"\"\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            r = _session.get(url, timeout=8, **kw)\n",
    "            if r.status_code == 200:\n",
    "                return r\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "        time.sleep(0.8)\n",
    "    return None\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ›ãƒ†ãƒ«ä¸€è¦§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def fetch_ids(base_url: str, slug: str, max_pages: int = 100, patience: int = 3):\n",
    "    ids = set(); stale = 0\n",
    "    for p in range(1, max_pages + 1):\n",
    "        res = http_get(base_url.format(slug=slug, page=p))\n",
    "        if not res:\n",
    "            break\n",
    "        before = len(ids)\n",
    "        ids.update(PAT_ID.findall(res.text))\n",
    "        stale = stale + 1 if len(ids) == before else 0\n",
    "        if stale >= patience:\n",
    "            break\n",
    "        time.sleep(random.uniform(*SLEEP_RANGE))\n",
    "    return ids\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ¬ãƒ“ãƒ¥ãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "LINK_SEL = \"p.reviewTitle a, h2.commentTitle a, div.rvTtl a, div.rvTltl a\"\n",
    "\n",
    "def fetch_reviews(hid: str):\n",
    "    reviews, seen = [], set()\n",
    "    for ym in MONTH_CODES:\n",
    "        for pg in range(MAX_PAGES_PER_M):\n",
    "            res = http_get(\n",
    "                f\"https://review.travel.rakuten.co.jp/hotel/voice/{hid}/\",\n",
    "                params={\"f_time\": ym, \"f_sort\": \"0\", \"f_next\": str(pg * REV_PAGE_SIZE)}\n",
    "            )\n",
    "            if not res:\n",
    "                break\n",
    "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "            for a in soup.select(LINK_SEL):\n",
    "                href = a.get(\"href\", \"\")\n",
    "                if href in seen:\n",
    "                    continue\n",
    "                seen.add(href)\n",
    "                det = http_get(href if href.startswith(\"http\") else \"https://review.travel.rakuten.co.jp\" + href)\n",
    "                if not det:\n",
    "                    continue\n",
    "                body = BeautifulSoup(det.text, \"html.parser\").select_one(\"p.commentSentence\")\n",
    "                if not body or TARGET_YEAR not in det.text:\n",
    "                    continue\n",
    "                reviews.append(body.get_text(strip=True))\n",
    "                if len(reviews) >= MAX_REV_HOTEL:\n",
    "                    return reviews\n",
    "            time.sleep(random.uniform(*SLEEP_RANGE))\n",
    "    return reviews\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ãƒ¡ã‚¤ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def main():\n",
    "    start = time.time()\n",
    "    rows = []\n",
    "\n",
    "    for slug in PREF_SLUGS:\n",
    "        print(f\"ğŸŒ {slug}\")\n",
    "        ids = list(fetch_ids(LIST_UI, slug))\n",
    "        if len(ids) < 150:\n",
    "            ids = list(set(ids) | fetch_ids(LIST_FALLBACK, slug, 60, 3))\n",
    "        random.shuffle(ids)\n",
    "\n",
    "        need = MAX_PER_PREF\n",
    "        idx = 0\n",
    "        with ThreadPoolExecutor(MAX_WORKERS) as pool:\n",
    "            while need > 0 and idx < len(ids):\n",
    "                batch_ids = ids[idx: idx + MAX_HOTELS_PER_BATCH]\n",
    "                idx += MAX_HOTELS_PER_BATCH\n",
    "                futures = {pool.submit(fetch_reviews, hid): hid for hid in batch_ids}\n",
    "\n",
    "                for fut in as_completed(futures):\n",
    "                    revs = fut.result()\n",
    "                    hid = futures[fut]\n",
    "                    take = min(len(revs), need)\n",
    "                    for txt in revs[:take]:\n",
    "                        rows.append({\n",
    "                            \"hotel_id\": hid,\n",
    "                            \"prefecture\": slug,\n",
    "                            \"review_text\": txt\n",
    "                        })\n",
    "                    need -= take\n",
    "                    if need <= 0:\n",
    "                        # cancel all remaining futures in current batch\n",
    "                        for f in futures:\n",
    "                            f.cancel()\n",
    "                        break\n",
    "            print(f\"   âœ” collected {MAX_PER_PREF - need}/{MAX_PER_PREF}\")\n",
    "\n",
    "    # ä¿å­˜\n",
    "    pd.DataFrame(rows).to_csv(OUT_FILE, index=False, encoding=\"utf-8-sig\")\n",
    "    duration = (time.time() - start) / 60\n",
    "    print(f\"\\nå®Œäº† {len(rows)} ä»¶ / {duration:.1f} åˆ†  (WORKERS={MAX_WORKERS})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
